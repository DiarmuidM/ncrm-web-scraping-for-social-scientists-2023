{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ef86da-941f-47d7-9828-98e218d21c9f",
   "metadata": {},
   "source": [
    "# Web scraping for social scientists: Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f927e7-fc5a-4a00-9c55-4fe083182cd6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Computational methods for collecting, cleaning and analysing data are an increasingly important component of a social scientistâ€™s toolkit. Central to engaging in these methods is the ability to write readable and effective code using a programming language.\n",
    "\n",
    "In this lesson we apply the logic of web scraping to more sophisticated, genuine websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e870b-a9f8-497b-a4d5-158b8f6befd8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aims\n",
    "\n",
    "This lesson has two aims:\n",
    "1. Demonstrate how to use Python to collect data found on more complicated, realistic websites.\n",
    "2. Cultivate your computational thinking skills through coding examples. In particular, how to define and solve a data collection problem using a computational method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f37324-1820-4637-8f88-9c2577570a70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lesson details\n",
    "\n",
    "* **Level**: Introductory\n",
    "* **Time**: 40-60 minutes\n",
    "* **Pre-requisites**: [Example 1](https://github.com/DiarmuidM/ncrm-web-scraping-for-social-scientists-2023/blob/main/code/ncrm-web-scraping-example-1-2023-06-06.ipynb)\n",
    "* **Audience**: Researchers and analysts from any disciplinary background\n",
    "* **Learning outcomes**:\n",
    "    1. Understand the key steps and requirements for collecting data from web pages using computational methods.\n",
    "    2. Be able to use Python for requesting, parsing, extracting and saving data stored on a web page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e39cd-5792-4670-a97f-9520eb7813d0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Guide to using this resource\n",
    "\n",
    "This learning resource was built using <a href=\"https://jupyter.org/\" target=_blank>Jupyter Notebook</a>, an open-source software application that allows you to mix code, results and narrative in a single document. As <a href=\"https://jupyter4edu.github.io/jupyter-edu-book/\" target=_blank>Barba et al. (2019)</a> espouse:\n",
    "> In a world where every subject matter can have a data-supported treatment, where computational devices are omnipresent and pervasive, the union of natural language and computation creates compelling communication and learning opportunities.\n",
    "\n",
    "If you are familiar with Jupyter notebooks then skip ahead to the main content (*What is web-scraping?*). Otherwise, the following is a quick guide to navigating and interacting with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17550ad8-7396-4b11-80ca-ded234acc85f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interaction\n",
    "\n",
    "**You only need to execute the code that is contained in sections which are marked by `In []`.**\n",
    "\n",
    "To execute a cell, click or double-click the cell and press the `Run` button on the top toolbar (you can also use the keyboard shortcut Shift + Enter).\n",
    "\n",
    "Try it for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b244e-be3e-4404-a521-413af83573ad",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Enter your name and press enter:\")\n",
    "name = input()\n",
    "print(\"\\r\")\n",
    "print(\"Hello {}, enjoy learning more about Python and web-scraping!\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788c174-5ab6-4244-ae3c-f4dc2bdf3791",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Learn more\n",
    "\n",
    "Jupyter notebooks provide rich, flexible features for conducting and documenting your data analysis workflow. To learn more about additional notebook features, we recommend working through some of the <a href=\"https://github.com/darribas/gds19/blob/master/content/labs/lab_00.ipynb\" target=_blank>materials</a> provided by Dani Arribas-Bel at the University of Liverpool. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23585936-ad51-421f-9ab8-7033b2adde6d",
   "metadata": {},
   "source": [
    "## City of Edinburgh Council"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ce58d4-8d54-4ba0-a10f-2d3f750fa311",
   "metadata": {},
   "source": [
    "Python script for collecting, parsing and saving organisation data from: \n",
    "* https://www.edinburgh.gov.uk/directory/10258/other-warm-and-welcoming-locations\n",
    "* https://www.edinburgh.gov.uk/directory/10199/library-locations-and-opening-hours\n",
    "* https://www.edinburgh.gov.uk/cost-living/food-bank-information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684aa444-7183-4118-ab21-9381d753d0fe",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde357a-2584-4ec6-9467-0d7fa2262bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modules\n",
    "\n",
    "import string # module for working with ASCII and other strings\n",
    "import os # module for navigating your machine (e.g., file directories)\n",
    "import requests # module for requesting urls\n",
    "import json # module for working with JSON data structures\n",
    "import csv # module for working with csv files\n",
    "import pandas as pd  # module for working with dataframes\n",
    "from datetime import datetime as dt # module for working with dates and time\n",
    "from bs4 import BeautifulSoup as soup # module for parsing web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5e12e-6ffc-4164-99a3-ff10746e568c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "\n",
    "other_data = \"./data/\"\n",
    "la_data = \"./data/local-authorities/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95662c-1cfa-47a2-b7e6-8208677ec1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create data folders\n",
    "\n",
    "for folder in other_data, la_data:\n",
    "    try:\n",
    "        os.mkdir(folder)\n",
    "    except:\n",
    "        print(\"Unable to create {}: already exists\".format(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50221836-4537-4f83-9a17-55efadce8474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download date\n",
    "\n",
    "ddate = dt.now().strftime(\"%Y-%m-%d\")\n",
    "ddate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad4f41-3a68-4e15-bf0b-d6971646a642",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65882bf1-428b-436a-bf79-5fc25d0b50d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "header = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\"}\n",
    "base = \"https://www.edinburgh.gov.uk/directory/10199/a-to-z/\"\n",
    "abc = list(string.ascii_uppercase)\n",
    "\n",
    "org_list = []\n",
    "    \n",
    "for l in abc:\n",
    "    url = base + str(l)\n",
    "    print(url)\n",
    "    response = requests.get(url, headers=header) # request the web address\n",
    "    \n",
    "    if response.status_code==200:\n",
    "        orgs = soup(response.text, \"html.parser\")\n",
    "        try:\n",
    "            results = orgs.find(\"ul\", class_=\"list list--record\").find_all(\"li\")\n",
    "            for el in results:\n",
    "                name = el.find(\"a\").text\n",
    "                link = el.find(\"a\").get(\"href\")\n",
    "                obs = {\"org_name\": name, \"org_url\": link}\n",
    "                #print(obs)\n",
    "                org_list.append(obs)\n",
    "        except:\n",
    "             print(\"Could not find list of organisations\")\n",
    "            \n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e90aae-3293-41b1-b47f-03f143f19bc8",
   "metadata": {},
   "source": [
    "#### Specific libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d638ba-da35-4b12-92f6-aa290659c895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(org_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d4f29-7903-4c8b-864c-32096b4c261b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "org_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c95ab-b4cd-45fe-a64b-d6a0400566c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "org_details = []\n",
    "base = \"https://www.edinburgh.gov.uk\"\n",
    "for org in org_list:\n",
    "    url = base + org[\"org_url\"]\n",
    "    \n",
    "    response = requests.get(url, headers=header) # request the web address\n",
    "    if response.status_code==200:\n",
    "        soup_org = soup(response.text, \"html.parser\")\n",
    "        results = soup_org.find(\"dl\", class_=\"list list--definition definition\")\n",
    "        #print(results)\n",
    "        \n",
    "        dts = results.find_all(\"dt\")\n",
    "        dt_list = []\n",
    "        for dt in dts:\n",
    "            dt_list.append(dt.text.strip())\n",
    "            \n",
    "        dds = results.find_all(\"dd\")\n",
    "        dd_list = []\n",
    "        for dd in dds:\n",
    "            dd_list.append(dd.text.strip())\n",
    "        \n",
    "        obs = dict(zip(dt_list, dd_list))\n",
    "        obs[\"org_name\"] = org[\"org_name\"]\n",
    "        obs[\"org_url\"] = url\n",
    "        #print(obs)\n",
    "        \n",
    "        org_details.append(obs)\n",
    "    else:\n",
    "        print(\"Could not request webpage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc037f-655a-4039-b9f4-f5da2381e34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "org_details[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491c6b3-502e-43a0-94a0-90781262d1c7",
   "metadata": {},
   "source": [
    "#### Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840aa76-322a-41d8-b825-ff340a3aa032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outfile = la_data + \"coe-library-spaces-\" + ddate + \".json\"\n",
    "with open(outfile, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(org_details, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5c321-2774-4ca9-85eb-f307218bae4b",
   "metadata": {},
   "source": [
    "### Warm Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba885f-43f1-4eae-8f47-fd74708ef9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "header = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\"}\n",
    "base = \"https://www.edinburgh.gov.uk/directory/10258/a-to-z/\"\n",
    "abc = list(string.ascii_uppercase)\n",
    "\n",
    "org_list = []\n",
    "    \n",
    "for l in abc:\n",
    "    url = base + str(l)\n",
    "    response = requests.get(url, headers=header) # request the web address\n",
    "    \n",
    "    if response.status_code==200:\n",
    "        orgs = soup(response.text, \"html.parser\")\n",
    "        try:\n",
    "            results = orgs.find(\"ul\", class_=\"list list--record\").find_all(\"li\")\n",
    "            for el in results:\n",
    "                name = el.find(\"a\").text\n",
    "                link = el.find(\"a\").get(\"href\")\n",
    "                obs = {\"org_name\": name, \"org_url\": link}\n",
    "                #print(obs)\n",
    "                org_list.append(obs)\n",
    "        except:\n",
    "             print(\"Could not find list of organisations\")\n",
    "            \n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463fdf7-7980-4daa-8462-4ec06e1db350",
   "metadata": {},
   "source": [
    "#### Specific organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a0d71-d94d-417c-a259-cee165780c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(org_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6e92a-959d-4542-988c-ca10b5610ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "org_list[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e15ced-7ccd-49ff-b293-92332f5a62f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "org_details = []\n",
    "base = \"https://www.edinburgh.gov.uk\"\n",
    "for org in org_list:\n",
    "    url = base + org[\"org_url\"]\n",
    "    \n",
    "    response = requests.get(url, headers=header) # request the web address\n",
    "    if response.status_code==200:\n",
    "        soup_org = soup(response.text, \"html.parser\")\n",
    "        results = soup_org.find(\"dl\", class_=\"list list--definition definition\")\n",
    "        #print(results)\n",
    "        \n",
    "        dts = results.find_all(\"dt\")\n",
    "        dt_list = []\n",
    "        for dt in dts:\n",
    "            dt_list.append(dt.text.strip())\n",
    "            \n",
    "        dds = results.find_all(\"dd\")\n",
    "        dd_list = []\n",
    "        for dd in dds:\n",
    "            dd_list.append(dd.text.strip())\n",
    "        \n",
    "        obs = dict(zip(dt_list, dd_list))\n",
    "        obs[\"org_name\"] = org[\"org_name\"]\n",
    "        obs[\"org_url\"] = url\n",
    "        #print(obs)\n",
    "        \n",
    "        org_details.append(obs)\n",
    "    else:\n",
    "        print(\"Could not request webpage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c57565-ea3b-4686-96cb-3a1082860498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "org_details[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9320037d-f012-4aed-9b3b-7519fc04c818",
   "metadata": {},
   "source": [
    "#### Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955766cc-9339-4e5c-bd18-681b4e8ea8be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outfile = la_data + \"coe-warm-spaces-\" + ddate + \".json\"\n",
    "with open(outfile, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(org_details, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
